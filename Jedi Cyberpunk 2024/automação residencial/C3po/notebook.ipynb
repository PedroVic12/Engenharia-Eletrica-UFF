{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.11.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am listening...\n",
      "\u001b[H\u001b[2Jtempo resposta: 6.48 segundos\n",
      "\n",
      "\n",
      "You said: QUAIS SÃO AS PRINCIPAIS FORMAS DE ELETROMAGNETISMO\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1071313223393'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/1071313223393\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"0\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-east2\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/grpc/_channel.py:1160\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1154\u001b[0m (\n\u001b[1;32m   1155\u001b[0m     state,\n\u001b[1;32m   1156\u001b[0m     call,\n\u001b[1;32m   1157\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1158\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1159\u001b[0m )\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/grpc/_channel.py:1003\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1071313223393'.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2800:3f0:4004:807::200a%5D:443 {created_time:\"2024-04-08T16:56:30.380570509-03:00\", grpc_status:8, grpc_message:\"Quota exceeded for quota metric \\'Generate Content API requests per minute\\' and limit \\'GenerateContent request limit per minute for a region\\' of service \\'generativelanguage.googleapis.com\\' for consumer \\'project_number:1071313223393\\'.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 185\u001b[0m\n\u001b[1;32m    182\u001b[0m text \u001b[38;5;241m=\u001b[39m c3po\u001b[38;5;241m.\u001b[39mlisten()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text:\n\u001b[0;32m--> 185\u001b[0m     command_response \u001b[38;5;241m=\u001b[39m \u001b[43mcommand_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrespond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m command_response:\n\u001b[1;32m    187\u001b[0m         c3po\u001b[38;5;241m.\u001b[39mfalar(command_response, speed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 163\u001b[0m, in \u001b[0;36mCommandHandler.respond\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    160\u001b[0m     exit()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodeloTextoGenerativo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResponda apenas com texto simples sem markdown com numeração se possível\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m, in \u001b[0;36mC3PoAssistente.modeloTextoGenerativo\u001b[0;34m(self, txt)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodeloTextoGenerativo\u001b[39m(\u001b[38;5;28mself\u001b[39m, txt):\n\u001b[1;32m     25\u001b[0m     model_TextGenerator \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-pro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_TextGenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPensando...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/generativeai/generative_models.py:248\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:566\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    561\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    562\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmodel),)),\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/api_core/retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    369\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/api_core/retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    209\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1071313223393'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/1071313223393\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"0\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-east2\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n}\n]"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pyjokes\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "from pygame import mixer\n",
    "import threading\n",
    "from pydub import AudioSegment\n",
    "import google.generativeai as genai\n",
    "import playsound\n",
    "import time \n",
    "\n",
    "# Configuração da chave de API do Google Gemini\n",
    "GEMINI_KEY = \"AIzaSyAPAFeexSmww1GOHMAQ0fWsHqoSlIppnDI\"\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "class C3PoAssistente:\n",
    "    def __init__(self):\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.is_listening = True  # Flag para controlar se o assistente está ouvindo\n",
    "\n",
    "    def modeloTextoGenerativo(self, txt):\n",
    "        model_TextGenerator = genai.GenerativeModel('gemini-pro')\n",
    "        response = model_TextGenerator.generate_content(txt)\n",
    "        print(\"Pensando...\")\n",
    "        return response.text\n",
    "  \n",
    "    def ouvir(self):\n",
    "        self.play_listening_sound()\n",
    "        print(\"\\nI am listening...\")\n",
    "        # Tenta ouvir em até 3 tentativas\n",
    "        for i in range(3):\n",
    "            print(f\"Tentativa {i+1}/3\")\n",
    "            with sr.Microphone() as source:\n",
    "                os.system(\"clear\")\n",
    "                self.recognizer.pause_threshold = 1\n",
    "                self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "                audio = self.recognizer.listen(source)\n",
    "                try:\n",
    "                    text = self.recognizer.recognize_sphinx(audio, language=\"pt-BR\").upper()\n",
    "                    print(\"\\n\\nYou said:\", text)  # Imprime o texto ouvido\n",
    "                    self.is_listening = False\n",
    "                    return text\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"\\n\\nSorry, I did not get that.\")\n",
    "                except sr.RequestError:\n",
    "                    print(\"Sorry, the service is not available\")\n",
    "        print(\"Excedeu o número de tentativas.\")\n",
    "        return \"\"\n",
    "    \n",
    "    def listen(self):\n",
    "        self.is_listening = True  \n",
    "\n",
    "        timeout = time.time()\n",
    "        with sr.Microphone() as source:\n",
    "            os.system(\"clear\")\n",
    "            self.recognizer.pause_threshold = 1\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            audio = self.recognizer.listen(source, timeout=timeout + 10 - time.time())\n",
    "\n",
    "            try:\n",
    "                text = self.recognizer.recognize_google(audio, language=\"pt-BR\").upper()\n",
    "                if (round(time.time() - timeout, 2) >= 10):\n",
    "                    print(\"tempo esgotado\")\n",
    "                    print(f\"tempo : {round(time.time() - timeout, 2)} segundos\",)\n",
    "                    return \n",
    "                print(f\"tempo resposta: {round(time.time() - timeout, 2)} segundos\", )\n",
    "                print(\"\\n\\nYou said:\", text)  # Imprime o texto ouvido\n",
    "                self.is_listening = False\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"\\n\\nSorry, I did not get that.\")\n",
    "            except sr.RequestError:\n",
    "                print(\"Sorry, the service is not available\")\n",
    "\n",
    "\n",
    "    def falar(self, text, speed=False):\n",
    "        # Verificar se o assistente está atualmente ouvindo\n",
    "        if self.is_listening:\n",
    "            return\n",
    "        if self.is_listening == False:\n",
    "            # Gerar áudio com texto fornecido\n",
    "            tts = gTTS(text=text, lang='pt')\n",
    "            filename = \"voice.mp3\"\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "            tts.save(filename)\n",
    "            # Ajustar a velocidade do áudio, se necessário\n",
    "            if speed:\n",
    "                audio = AudioSegment.from_mp3(filename)\n",
    "                audio.speedup(playback_speed=1.5).export(filename, format=\"mp3\")\n",
    "            # Tocar o áudio\n",
    "            threading.Thread(target=playsound.playsound, args=(filename,)).start()\n",
    "            print(\"\\nC3PO: \", text)\n",
    "\n",
    "            #todo flag self.is_listening = True\n",
    "\n",
    "\n",
    "    def play_listening_sound(self):\n",
    "        # Tocar som simples para indicar que o assistente está ouvindo\n",
    "        self.is_listening = True  \n",
    "        playsound.playsound(\"./sounds/blip.mp3\")\n",
    "        playsound.playsound(\"./sounds/c3po_init.mp3\")\n",
    "\n",
    "        \n",
    "    def continuarConversa(self):\n",
    "        resp_Control = input(\" sim/nao: \").strip().lower()\n",
    "\n",
    "        if resp_Control == \"nao\":\n",
    "            c3po.falar(\"Até mais, mestre Pedro!\", speed=True)\n",
    "            return False\n",
    "        else:\n",
    "            c3po.falar(\"Precisa de algo mais, mestre?\", speed=True)\n",
    "            c3po.is_listening = True\n",
    "            time.sleep(4)\n",
    "\n",
    "class CommandHandler:\n",
    "    def __init__(self):\n",
    "        self.robo = C3PoAssistente()\n",
    "\n",
    "    def respond(self, text):\n",
    "        if \"C3PO\" in text or \"assistente\" in text:\n",
    "            self.robo.falar(\"Olá mestre Pedro, estou à sua disposição. Como posso ajudar?\")\n",
    "            return\n",
    "\n",
    "        if 'youtube' in text:\n",
    "            webbrowser.get().open(\"https://www.youtube.com\")\n",
    "            return\n",
    "\n",
    "        elif 'pesquisar' in text:\n",
    "            query = text.replace('pesquisar', '').strip()\n",
    "            result = wikipedia.summary(query, sentences=3)\n",
    "            print(result)\n",
    "            self.robo.falar(result)\n",
    "            return\n",
    "\n",
    "\n",
    "        elif 'horas' in text:\n",
    "            strTime = datetime.today().strftime(\"%H:%M %p\")\n",
    "            self.robo.falar(strTime)\n",
    "            return\n",
    "\n",
    "        elif 'tocar música' in text or 'play song' in text:\n",
    "            music_dir = \"/home/pedrov/Músicas/\"\n",
    "            songs = os.listdir(music_dir)\n",
    "            print(songs)\n",
    "            self.playmusic(music_dir + songs[0])\n",
    "            return\n",
    "\n",
    "        elif 'parar música' in text or 'stop music' in text:\n",
    "            self.stopmusic()\n",
    "            return\n",
    "\n",
    "        elif 'sair' in text or 'exit' in text:\n",
    "            self.robo.falar(\"Adeus, até a próxima!\")\n",
    "            exit()\n",
    "        \n",
    "        else:\n",
    "            return self.robo.modeloTextoGenerativo(\"Responda apenas com texto simples sem markdown com numeração se possível\" + text)\n",
    "\n",
    "    def playmusic(self, song):\n",
    "        mixer.init()\n",
    "        mixer.music.load(song)\n",
    "        mixer.music.play()\n",
    "\n",
    "    def stopmusic(self):\n",
    "        mixer.music.stop()\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "c3po = C3PoAssistente()\n",
    "command_handler = CommandHandler()\n",
    "c3po.play_listening_sound()\n",
    "\n",
    "while True:\n",
    "    if c3po.is_listening:\n",
    "        print(\"\\nI am listening...\")\n",
    "        text = c3po.listen()\n",
    "\n",
    "        if text:\n",
    "            command_response = command_handler.respond(text.lower())\n",
    "            if command_response:\n",
    "                c3po.falar(command_response, speed=True)\n",
    "            else:\n",
    "                print(\"Desculpe, não entendi.\")\n",
    "\n",
    "        flag = c3po.continuarConversa()\n",
    "        if flag == False:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am listening...\n",
      "\u001b[H\u001b[2Jtempo resposta: 4.02 segundos\n",
      "\n",
      "\n",
      "You said: YOUTUBE\n",
      "pensando...\n",
      "\n",
      "C3PO:  1. YouTube\n",
      "\n",
      "C3PO:  Precisa de algo mais, mestre?\n",
      "\n",
      "I am listening...\n",
      "\u001b[H\u001b[2Jtempo esgotado\n",
      "tempo : 30.99 segundos\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 178\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mI am listening...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m text \u001b[38;5;241m=\u001b[39m c3po\u001b[38;5;241m.\u001b[39mlisten()\n\u001b[0;32m--> 178\u001b[0m command_handler\u001b[38;5;241m.\u001b[39mrespond(\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m())\n\u001b[1;32m    180\u001b[0m response \u001b[38;5;241m=\u001b[39m  c3po\u001b[38;5;241m.\u001b[39mmodeloTextoGenerativo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponda apenas com texto simples sem markdown com numeração se possível\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m text)\n\u001b[1;32m    181\u001b[0m c3po\u001b[38;5;241m.\u001b[39mfalar(response, speed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pyjokes\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "from pygame import mixer\n",
    "import threading\n",
    "from pydub import AudioSegment\n",
    "import google.generativeai as genai\n",
    "import playsound\n",
    "import time \n",
    "\n",
    "# Configuração da chave de API do Google Gemini\n",
    "GEMINI_KEY = \"AIzaSyAPAFeexSmww1GOHMAQ0fWsHqoSlIppnDI\"\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "\n",
    "class C3PoAssistente:\n",
    "    def __init__(self):\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.is_listening = True  # Flag para controlar se o assistente está ouvindo\n",
    "\n",
    "    def modeloTextoGenerativo(self, txt):\n",
    " \n",
    "        model_TextGenerator = genai.GenerativeModel('gemini-pro')\n",
    "        response = model_TextGenerator.generate_content(txt)\n",
    "        print(\"pensando...\")\n",
    "        return response.text\n",
    "  \n",
    "    def ouvir(self):\n",
    "        self.play_listening_sound()\n",
    "        print(c3po.is_listening)\n",
    "        print(\"\\nI am listening...\")\n",
    "        # Tenta ouvir em até 3 tentativas\n",
    "        for i in range(3):\n",
    "            print(f\"Tentativa {i+1}/3\")\n",
    "            with sr.Microphone() as source:\n",
    "                os.system(\"clear\")\n",
    "                self.recognizer.pause_threshold = 1\n",
    "                self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "                audio = self.recognizer.listen(source)\n",
    "                try:\n",
    "                    text = self.recognizer.recognize_sphinx(audio, language=\"pt-BR\").upper()\n",
    "                    print(\"\\n\\nYou said:\", text)  # Imprime o texto ouvido\n",
    "                    self.is_listening = False\n",
    "                    return text\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"\\n\\nSorry, I did not get that.\")\n",
    "                except sr.RequestError:\n",
    "                    print(\"Sorry, the service is not available\")\n",
    "        print(\"Excedeu o número de tentativas.\")\n",
    "        return \"\"\n",
    "    \n",
    "    def listen(self):\n",
    "        self.is_listening = True  \n",
    "\n",
    "        timeout = time.time()\n",
    "        with sr.Microphone() as source:\n",
    "            os.system(\"clear\")\n",
    "            self.recognizer.pause_threshold = 1\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            audio = self.recognizer.listen(source, timeout=timeout + 10 - time.time())\n",
    "\n",
    "            try:\n",
    "                text = self.recognizer.recognize_google(audio, language=\"pt-BR\").upper()\n",
    "                if (round(time.time() - timeout, 2) >= 10):\n",
    "                    print(\"tempo esgotado\")\n",
    "                    print(f\"tempo : {round(time.time() - timeout, 2)} segundos\",)\n",
    "                    return \n",
    "                print(f\"tempo resposta: {round(time.time() - timeout, 2)} segundos\", )\n",
    "                print(\"\\n\\nYou said:\", text)  # Imprime o texto ouvido\n",
    "                self.is_listening = False\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"\\n\\nSorry, I did not get that.\")\n",
    "            except sr.RequestError:\n",
    "                print(\"Sorry, the service is not available\")\n",
    "\n",
    "\n",
    "    def falar(self, text, speed=False):\n",
    "        # Verificar se o assistente está atualmente ouvindo\n",
    "        if self.is_listening:\n",
    "            return\n",
    "        if self.is_listening == False:\n",
    "            # Gerar áudio com texto fornecido\n",
    "            tts = gTTS(text=text, lang='pt')\n",
    "            filename = \"voice.mp3\"\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "            tts.save(filename)\n",
    "            # Ajustar a velocidade do áudio, se necessário\n",
    "            if speed:\n",
    "                audio = AudioSegment.from_mp3(filename)\n",
    "                audio.speedup(playback_speed=1.5).export(filename, format=\"mp3\")\n",
    "            # Tocar o áudio\n",
    "            threading.Thread(target=playsound.playsound, args=(filename,)).start()\n",
    "            print(\"\\nC3PO: \", text)\n",
    "\n",
    "            #todo flag self.is_listening = True\n",
    "\n",
    "\n",
    "    def play_listening_sound(self):\n",
    "        # Tocar som simples para indicar que o assistente está ouvindo\n",
    "        self.is_listening = True  \n",
    "        playsound.playsound(\"./sounds/blip.mp3\")\n",
    "        playsound.playsound(\"./sounds/c3po_init.mp3\")\n",
    "\n",
    "        \n",
    "    def continuarConversa(self):\n",
    "            #c3po.is_listening = False\n",
    "        resp_Control = input(\" sim/nao: \").strip().lower()\n",
    "\n",
    "        if resp_Control == \"nao\":\n",
    "            c3po.falar(\"Até mais, mestre Pedro!\", speed=True)\n",
    "            return False\n",
    "        else:\n",
    "            c3po.falar(\"Precisa de algo mais, mestre?\", speed=True)\n",
    "            c3po.is_listening = True\n",
    "            time.sleep(4)\n",
    "\n",
    "class CommandHandler:\n",
    "    def __init__(self):\n",
    "        self.robo = C3PoAssistente()\n",
    "\n",
    "    def respond(self, text):\n",
    "        if \"C3PO\" or \"assistente\" in text:\n",
    "            self.robo.falar(\"Ola mestre Pedro, estou a sua disposição. Como posso ajudar?\")\n",
    "            exit()\n",
    "\n",
    "        if 'youtube' in text:\n",
    "            webbrowser.get().open(\"https://www.youtube.com\")\n",
    "\n",
    "        elif 'pesquisar' in text:\n",
    "            query = text.replace('search', '').strip()\n",
    "            result = wikipedia.summary(query, sentences=3)\n",
    "            print(result)\n",
    "            self.robo.falar(result)\n",
    "        elif 'me conte uma piada' or \"piada\" in text:\n",
    "            self.robo.falar(pyjokes.get_joke())\n",
    "        elif 'horas' in text:\n",
    "            strTime = datetime.today().strftime(\"%H:%M %p\")\n",
    "            self.robo.falar(strTime)\n",
    "        elif 'tocar musica' in text or 'play song' in text:\n",
    "            music_dir = \"/home/pedrov/Músicas/\"\n",
    "            songs = os.listdir(music_dir)\n",
    "            print(songs)\n",
    "            self.playmusic(music_dir + songs[0])\n",
    "        elif 'stop music' in text:\n",
    "            self.stopmusic()\n",
    "        elif 'exit' in text:\n",
    "            self.robo.falar(\"Goodbye, till next time\")\n",
    "            exit()\n",
    "\n",
    "    def playmusic(self, song):\n",
    "        mixer.init()\n",
    "        mixer.music.load(song)\n",
    "        mixer.music.play()\n",
    "\n",
    "    def stopmusic(self):\n",
    "        mixer.music.stop()\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "c3po = C3PoAssistente()\n",
    "command_handler = CommandHandler()\n",
    "c3po.play_listening_sound()\n",
    "\n",
    "while True:\n",
    "    if c3po.is_listening:\n",
    "        print(\"\\nI am listening...\")\n",
    "        text = c3po.listen()\n",
    "\n",
    "        command_handler.respond(text.lower())\n",
    "\n",
    "        response =  c3po.modeloTextoGenerativo(\"Responda apenas com texto simples sem markdown com numeração se possível\" + text)\n",
    "        c3po.falar(response, speed=True)\n",
    "\n",
    "        flag = c3po.continuarConversa()\n",
    "        if flag == False:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
